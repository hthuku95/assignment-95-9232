content='import os\nimport logging\nfrom typing import List, Dict, Optional, Any, Tuple\nimport numpy as np\nfrom datetime import datetime\nimport chromadb\nfrom chromadb.config import Settings\nfrom chromadb.utils import embedding_functions\nimport google.generativeai as genai\nfrom google.generativeai import embed_content\nfrom google.generativeai.types import TaskType\n\nlogger = logging.getLogger(__name__)\n\nclass VectorDBService:\n    """\n    Vector database service for managing the tutor_space_projects_3072 collection.\n    Handles document storage, retrieval, and similarity search using Google Gemini embeddings.\n    """\n    \n    def __init__(self, collection_name: str = "tutor_space_projects_3072"):\n        """\n        Initialize the vector database service.\n        \n        Args:\n            collection_name: Name of the ChromaDB collection to use\n        """\n        self.collection_name = collection_name\n        self.embedding_dimension = 3072\n        self.embedding_model = "models/gemini-embedding-001"\n        \n        # Configure Google Gemini API\n        api_key = os.getenv(\'GOOGLE_API_KEY\')\n        if not api_key:\n            raise ValueError("GOOGLE_API_KEY environment variable is required")\n        \n        genai.configure(api_key=api_key)\n        \n        # Initialize ChromaDB client\n        self._initialize_chroma_client()\n        self._initialize_collection()\n    \n    def _initialize_chroma_client(self):\n        """Initialize ChromaDB client with proper configuration."""\n        try:\n            # Use persistent client for production\n            persist_directory = os.getenv(\'CHROMA_PERSIST_DIRECTORY\', \'./chroma_db\')\n            \n            self.client = chromadb.PersistentClient(\n                path=persist_directory,\n                settings=Settings(\n                    anonymized_telemetry=False,\n                    allow_reset=True\n                )\n            )\n            logger.info(f"ChromaDB client initialized with persist directory: {persist_directory}")\n            \n        except Exception as e:\n            logger.error(f"Failed to initialize ChromaDB client: {e}")\n            raise\n    \n    def _initialize_collection(self):\n        """Initialize or get the collection with Google Gemini embedding function."""\n        try:\n            # Create custom embedding function for Google Gemini\n            embedding_function = self._create_gemini_embedding_function()\n            \n            # Get or create collection\n            try:\n                self.collection = self.client.get_collection(\n                    name=self.collection_name,\n                    embedding_function=embedding_function\n                )\n                logger.info(f"Retrieved existing collection: {self.collection_name}")\n            except ValueError:\n                # Collection doesn\'t exist, create it\n                self.collection = self.client.create_collection(\n                    name=self.collection_name,\n                    embedding_function=embedding_function,\n                    metadata={"hnsw:space": "cosine", "dimension": self.embedding_dimension}\n                )\n                logger.info(f"Created new collection: {self.collection_name}")\n                \n        except Exception as e:\n            logger.error(f"Failed to initialize collection: {e}")\n            raise\n    \n    def _create_gemini_embedding_function(self):\n        """Create a custom embedding function for Google Gemini."""\n        class GeminiEmbeddingFunction(embedding_functions.EmbeddingFunction):\n            def __call__(self, input: List[str]) -> List[List[float]]:\n                embeddings = []\n                for text in input:\n                    try:\n                        # Use RETRIEVAL_DOCUMENT task type for document embeddings\n                        result = embed_content(\n                            model="models/gemini-embedding-001",\n                            content=text,\n                            task_type=TaskType.RETRIEVAL_DOCUMENT,\n                            title=None\n                        )\n                        embeddings.append(result[\'embedding\'])\n                    except Exception as e:\n                        logger.error(f"Failed to generate embedding for text: {e}")\n                        # Return zero vector as fallback\n                        embeddings.append([0.0] * 3072)\n                return embeddings' additional_kwargs={} response_metadata={'id': 'msg_014R9rDiyCFsWDV6q6gLewzb', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'max_tokens', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 418, 'output_tokens': 1024, 'service_tier': 'standard'}} id='run--42b3dfa0-2d54-4f44-a2fe-1f4d3c749a72-0' usage_metadata={'input_tokens': 418, 'output_tokens': 1024, 'total_tokens': 1442, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}